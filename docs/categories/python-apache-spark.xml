<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Software Lobotomy (Posts about python apache-spark)</title><link>https://parisni.github.io/weblog/</link><description></description><atom:link href="https://parisni.github.io/weblog/categories/python-apache-spark.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2018 &lt;a href="mailto:nicolas.paris@riseup.net"&gt;Parisni&lt;/a&gt; </copyright><lastBuildDate>Thu, 22 Nov 2018 22:35:12 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>PySpark Considerations</title><link>https://parisni.github.io/weblog/posts/pyspark-considerations/</link><dc:creator>Parisni</dc:creator><description>&lt;div class="section" id="extracting-raw-data-from-hdfs"&gt;
&lt;h2&gt;Extracting raw data from hdfs&lt;/h2&gt;
&lt;p&gt;I have tested multiple ways to get data from hdfs. There is two situations:&lt;/p&gt;
&lt;div class="section" id="the-data-fits-in-a-local-node-ram-memory"&gt;
&lt;h3&gt;The data fits in a local node RAM memory:&lt;/h3&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# will produce a local csv&lt;/span&gt;
&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"select * from my_table where true"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-3"&gt;&lt;/a&gt;    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toPandas&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-4"&gt;&lt;/a&gt;    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"myLocalFile.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"utf8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-5"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# otherwise spark shell keeps running&lt;/span&gt;
&lt;a name="rest_code_51f804ddea2b4fe09d3291f0ff503e11-6"&gt;&lt;/a&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code bash"&gt;&lt;a name="rest_code_58dd4ae1b0764df29554e71574f89967-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# run the python script:&lt;/span&gt;
&lt;a name="rest_code_58dd4ae1b0764df29554e71574f89967-2"&gt;&lt;/a&gt;&lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;my/python/path/prog.py pyspark --master yarn &lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="the-dataset-does-not-fit-into-ram-memory"&gt;
&lt;h3&gt;The dataset does not fit into RAM memory:&lt;/h3&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# will produce some csv on hdfs&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"select * from my_table where true"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-3"&gt;&lt;/a&gt;    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-4"&gt;&lt;/a&gt;    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-5"&gt;&lt;/a&gt;    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"/output/dir/on/hdfs/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-6"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# otherwise spark shell keeps running&lt;/span&gt;
&lt;a name="rest_code_b01158ce34c243d9b42ed55248d8a666-7"&gt;&lt;/a&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code bash"&gt;&lt;a name="rest_code_36ddc5e6294141c185c3c77511bc0468-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# run the python script:&lt;/span&gt;
&lt;a name="rest_code_36ddc5e6294141c185c3c77511bc0468-2"&gt;&lt;/a&gt;&lt;span class="nv"&gt;PYTHONPATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;my/python/path/prog.py pyspark --master yarn &lt;span class="o"&gt;[&lt;/span&gt;...&lt;span class="o"&gt;]&lt;/span&gt;
&lt;a name="rest_code_36ddc5e6294141c185c3c77511bc0468-3"&gt;&lt;/a&gt;&lt;span class="c1"&gt;# merge the files on the local filesystem&lt;/span&gt;
&lt;a name="rest_code_36ddc5e6294141c185c3c77511bc0468-4"&gt;&lt;/a&gt;hadoop fs -getmerge /output/dir/on/hdfs/ /desired/local/output/file.csv
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;</description><category>python apache-spark</category><guid>https://parisni.github.io/weblog/posts/pyspark-considerations/</guid><pubDate>Thu, 22 Nov 2018 22:05:23 GMT</pubDate></item></channel></rss>