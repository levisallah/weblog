<!DOCTYPE html>
<html prefix="
        og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Loading Postgres from Sqoop | Software Lobotomy</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://parisni.github.io/weblog/posts/loading-postgres-from-sqoop/">
<!--[if lt IE 9]><script src="../../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><meta name="author" content="Parisni">
<link rel="prev" href="../deploying-with-githup-pages/" title="Deploying Nikola with Githup Pages" type="text/html">
<link rel="next" href="../jupyter-notebooks-and-conda/" title="Jupyter Notebooks and Conda" type="text/html">
<meta property="og:site_name" content="Software Lobotomy">
<meta property="og:title" content="Loading Postgres from Sqoop">
<meta property="og:url" content="https://parisni.github.io/weblog/posts/loading-postgres-from-sqoop/">
<meta property="og:description" content="PostgreSQL and Hadoop are complementary technologies. PostgreSQL outperforms
Hadoop to retrieve small amount of information from multiple tables. Hadoop
outperforms PostgreSQL to transform multiple ta">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-11-11T21:19:55+01:00">
<meta property="article:tag" content="big-data">
<meta property="article:tag" content="hadoop">
<meta property="article:tag" content="postgresql">
<meta property="article:tag" content="sqoop">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
             <header id="header"><h1 id="brand"><a href="https://parisni.github.io/weblog/" title="Software Lobotomy" rel="home">

        <span id="blog-title">Software Lobotomy</span>
    </a></h1>

        
            <nav id="menu"><ul>
<li><a href="../../categories/">Tags</a></li>
                <li><a href="../../archive.html">Archive</a></li>
                <li><a href="../../stories/about/">About</a></li>
                <li><a href="../../rss.xml">RSS</a></li>

    
    
    
    </ul></nav></header><main id="content"><article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Loading Postgres from Sqoop</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Parisni
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2018-11-11T21:19:55+01:00" itemprop="datePublished" title="2018-11-11">2018-11-11</time></a>
            </p>
                <p class="commentline">            <a href="#disqus_thread" data-disqus-identifier="cache/posts/loading-postgres-from-sqoop.html">Comments</a>


            
        </p>
</div>
        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>PostgreSQL and Hadoop are complementary technologies. PostgreSQL outperforms
Hadoop to retrieve small amount of information from multiple tables. Hadoop
outperforms PostgreSQL to transform multiple tables into simplfied and
aggregated tables. So, how to load PostgreSQL efficiently from Hadoop ?</p>
<!-- END_TEASER -->
<div class="section" id="sqoop-as-a-bridge">
<h2>Sqoop as a bridge</h2>
<p>Hadoop stores data on its distributed filesystem: HDFS. At the end of the day,
the resulting procecced data is stored into a hdfs table and may need to be
loaded into a PosgreSQL table.</p>
<p>Copy is a efficient a robust PostgreSQL bulkloading function allowing to load
among from others CSV files. It is way faster than a bunch of parallel prepared
insert statements.</p>
<p>ORC is a efficient and compressed Hadoop data format. It is both faster to
build and to read compared to CSV files.</p>
<p>As the bridge for Hadoop and relational databases, Sqoop manages all ORC, CSV,
COPY and INSERT methodologies. When dealing with PostgreSQL, there is no
perfect solution.</p>
</div>
<div class="section" id="sqoop-best-approach">
<h2>Sqoop best approach</h2>
<p>There is two different scenario to load PostgreSQL.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">structured columns:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">Sqoop does not allow to use COPY together with ORC tables
but only with CSV. It splits them and run multiple COPY
statements from each part in parallel from HDFS. The CSV
format needs to be defined in the sqoop parameters.</td>
</tr>
<tr class="field"><th class="field-name" colspan="2">unstructured columns:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">Text information may contain new lines. In this
situation, Sqoop is stuck when it splits the CSV into
multiple parts. Yet it is not possible to use the sqoop
direct mode, and the parallel inserts is the only way to
succeed. By chance, it is not necessar to transform the
result as CSV, and it is finally possible to exploit ORC
tables as-is.</td>
</tr>
</tbody>
</table>
<p>Writing this post makes me thinking about a potential workaround to load
textual CSV from COPY by using only one mapper in this situation. Since COPY is
highly optimized it is possible that it won't degrade the performances while
making the overall process totally robust.</p>
<p>EDIT:</p>
<p>Indeed, using only one mapper allows to handle multiline CSV. Since COPY is
very fast and has been optimized to import dataset into postgreSQL, in the
general case, the method can be generalized to any kind of CSV to work in any
situation. That's the ultimate way to load PostgreSQL from Hadoop:</p>
<pre class="code bash"><a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-1"></a>sqoop export<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-2"></a>--connect <span class="s2">"jdbc:postgresql://&lt;postgres_host&gt;/&lt;postgres_db&gt;"</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-3"></a>--username &lt;postgres_user&gt;<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-4"></a>--password-file file:///home/<span class="nv">$USER</span>/.password<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-5"></a>--export-dir /apps/hive/warehouse/&lt;my_db&gt;/&lt;my_csv_table&gt;<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-6"></a>--table &lt;my_postgres_table&gt;<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-7"></a>--columns <span class="s2">"id, text_column"</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-8"></a>-m <span class="m">1</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-9"></a>--direct<span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-10"></a>--lines-terminated-by <span class="s1">'\n'</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-11"></a>--fields-terminated-by <span class="s1">','</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-12"></a>--input-null-string <span class="s2">"\\\\N"</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-13"></a>--input-null-non-string <span class="s2">"\\\\N"</span><span class="se">\</span>
<a name="rest_code_c2aa23d7a23e4563aba853bb118f85c9-14"></a>-- --schema &lt;my_schema&gt;
</pre>
<p>In order to prepare the table ready to be loaded by sqoop, it can be
transformed with a hive sql query:</p>
<pre class="code sql"><a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-1"></a><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="o">&lt;</span><span class="n">my_db</span><span class="o">&gt;</span><span class="p">.</span><span class="o">&lt;</span><span class="n">my_csv_table</span><span class="o">&gt;</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-2"></a><span class="n">STORED</span> <span class="k">AS</span> <span class="n">textfile</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-3"></a><span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">DELIMITED</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-4"></a><span class="n">FIELDS</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">','</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-5"></a><span class="n">LINES</span> <span class="n">TERMINATED</span> <span class="k">BY</span> <span class="s1">'\n'</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-6"></a><span class="k">AS</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-7"></a><span class="k">SELECT</span> <span class="o">*</span>
<a name="rest_code_65cd6a10409240b8bdedc4a781584cd8-8"></a><span class="k">FROM</span> <span class="o">&lt;</span><span class="n">my_hive_table</span><span class="o">&gt;</span>
</pre>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/big-data/" rel="tag">big-data</a></li>
            <li><a class="tag p-category" href="../../categories/hadoop/" rel="tag">hadoop</a></li>
            <li><a class="tag p-category" href="../../categories/postgresql/" rel="tag">postgresql</a></li>
            <li><a class="tag p-category" href="../../categories/sqoop/" rel="tag">sqoop</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../deploying-with-githup-pages/" rel="prev" title="Deploying Nikola with Githup Pages">Previous post</a>
            </li>
            <li class="next">
                <a href="../jupyter-notebooks-and-conda/" rel="next" title="Jupyter Notebooks and Conda">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="softwareLobotomy",
            disqus_url="https://parisni.github.io/weblog/posts/loading-postgres-from-sqoop/",
        disqus_title="Loading Postgres from Sqoop",
        disqus_identifier="cache/posts/loading-postgres-from-sqoop.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="softwareLobotomy";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script></main>
</div>
                <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
